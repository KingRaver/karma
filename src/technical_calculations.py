#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ðŸ”¥ TECHNICAL_CALCULATIONS.PY - OPTIMIZED CALCULATION ENGINES ðŸ”¥
============================================================================
Technical Analysis Calculation System
Optimized for integration with prediction_engine.py and bot.py

SYSTEM ARCHITECTURE:
ðŸ—ï¸ Foundation-based architecture with robust fallback handling
ðŸ”¢ Optimized mathematical kernels for performance
ðŸ“Š Array standardization and validation systems
ðŸ”„ 100% backward compatibility with existing systems

INTEGRATION FEATURES:
âœ… Seamless integration with prediction_engine.py
âœ… Perfect compatibility with bot.py analysis workflows
âœ… Advanced caching and performance monitoring

Author: Technical Analysis Master System
Version: 8.0 - Optimized Edition
Compatible with: prediction_engine.py, bot.py, technical_foundation.py
"""

import sys
import os
import time
import math
import warnings
import threading
import hashlib
from typing import Dict, List, Any, Optional, Union, Tuple, Callable
from datetime import datetime, timedelta

# ============================================================================
# ðŸ”§ DEPENDENCY IMPORTS ðŸ”§
# ============================================================================

# Initialize availability flags with proper foundation import
try:
    from technical_foundation import (
        M4_ULTRA_MODE,
        OPTIMAL_WORKERS,  # Get the REAL value from foundation (10 from M4 detection)
        NUMPY_AVAILABLE,
        NUMBA_AVAILABLE,
        logger,
        m4_libs
    )
    FOUNDATION_AVAILABLE = True
    logger.info("âœ… technical_calculations.py: Foundation import successful")
except ImportError as e:
    # Only use fallbacks if foundation is completely unavailable
    FOUNDATION_AVAILABLE = False
    M4_ULTRA_MODE = False
    OPTIMAL_WORKERS = 10  # Fallback - but this should rarely be used
    logger = None
    m4_libs = None
    print(f"âš ï¸ technical_calculations.py: Foundation import failed: {e}")
    print("ðŸ’¡ Using fallback values - performance will be degraded")

# Advanced numerical libraries
import numpy as np
NUMPY_AVAILABLE = True

try:
    from technical_foundation import (
        logger as foundation_logger, 
        M4_ULTRA_MODE,
        OPTIMAL_WORKERS,
        validate_price_data,
        safe_division, 
        format_currency,
        m4_libs
    )
    
    from database import get_database_instance
    
    logger = foundation_logger
    database = get_database_instance()
    FOUNDATION_AVAILABLE = True
    
    if logger:
        logger.info("ðŸ—ï¸ Foundation module successfully imported")
        logger.info(f"ðŸ”¥ M4 Ultra Mode: {'ENABLED' if M4_ULTRA_MODE else 'DISABLED'}")
        logger.info(f"ðŸ§µ Using OPTIMAL_WORKERS: {OPTIMAL_WORKERS} threads (from foundation)")
        
except ImportError as e:
    FOUNDATION_AVAILABLE = False
    M4_ULTRA_MODE = False
    m4_libs = None
    
    # INDUSTRY STANDARD FALLBACK: Use consistent fallback value
    # NEVER use raw CPU count here - use conservative fallback
    if 'OPTIMAL_WORKERS' not in globals():
        OPTIMAL_WORKERS = 10  # Industry standard fallback - NEVER use multiprocessing.cpu_count()
    
    print(f"âš ï¸ technical_calculations.py: Foundation import failed: {e}")
    print(f"ðŸ’¡ Using fallback configuration with {OPTIMAL_WORKERS} threads - some features will be degraded")
    
    # Create basic logger if none exists
    if 'logger' not in globals() or logger is None:
        import logging
        logger = logging.getLogger("technical_calculations_fallback")
        logger.setLevel(logging.INFO)
    
    # Create basic logging system
    import logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s | %(name)s | %(levelname)s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    logger = logging.getLogger("TechnicalCalculations")
    logger.warning(f"Foundation module not available: {e}")
    logger.info(f"ðŸ§µ Using fallback OPTIMAL_WORKERS: {OPTIMAL_WORKERS} threads")
    
    # Try to import database separately
    try:
        from database import get_database_instance
        database = get_database_instance()
        logger.info("âœ… Database imported independently")
    except ImportError:
        database = None
        logger.warning("âš ï¸ Database unavailable")

# INDUSTRY STANDARD THREAD MANAGEMENT - GLOBAL THREAD MANAGER PRIMARY SYSTEM
if M4_ULTRA_MODE and NUMPY_AVAILABLE:
    try:
        # PRIMARY: Use the global thread manager for ALL NUMBA operations
        from numba_thread_manager import get_global_manager
        thread_manager = get_global_manager()
        
        # FIXED: Always use OPTIMAL_WORKERS consistently
        if not thread_manager.is_configured():
            success = thread_manager.initialize(
                thread_count=OPTIMAL_WORKERS,  # Use foundation's OPTIMAL_WORKERS (10)
                enable_parallel=True,
                enable_fastmath=True,
                enable_cache=True,
                enable_avx=True
            )
            if success:
                thread_manager.lock_configuration()
                logger.info(f"ðŸ”’ Global thread manager initialized and locked with {OPTIMAL_WORKERS} threads")
            else:
                logger.warning("âš ï¸ Thread manager initialization failed, using fallback")
        else:
            # Verify existing configuration matches
            current_threads = thread_manager.get_thread_count()
            if current_threads != OPTIMAL_WORKERS:
                logger.warning(f"ðŸš¨ Thread count mismatch detected: manager={current_threads}, expected={OPTIMAL_WORKERS}")
        
        # Get thread-safe decorators from the global manager
        njit = thread_manager.get_njit()
        prange = thread_manager.get_prange()
        NUMBA_AVAILABLE = True
        logger.info(f"ðŸš€ Using global NUMBA thread manager ({OPTIMAL_WORKERS} threads)")
        
    except ImportError as thread_mgr_error:
        logger.warning(f"âš ï¸ Thread manager unavailable: {thread_mgr_error}")
        
        # Secondary fallback: try foundation's thread-safe decorators
        try:
            if FOUNDATION_AVAILABLE and m4_libs and hasattr(m4_libs, 'njit'):
                # Use pre-configured foundation decorators that respect OPTIMAL_WORKERS
                njit = m4_libs.njit
                prange = m4_libs.prange
                NUMBA_AVAILABLE = True
                logger.info(f"ðŸš€ Using thread-safe NUMBA from foundation ({OPTIMAL_WORKERS} threads)")
            else:
                raise ImportError("Foundation decorators unavailable")
        except (ImportError, AttributeError):
            # CRITICAL WARNING: Direct NUMBA import causes threading conflicts
            logger.error("ðŸš¨ CRITICAL WARNING: Using direct NUMBA import - THIS CAUSES THREAD CONFLICTS!")
            logger.error("ðŸš¨ This will result in 'Cannot set NUMBA_NUM_THREADS' errors")
            logger.error(f"ðŸš¨ System will attempt to use raw CPU count instead of {OPTIMAL_WORKERS} threads")
            
            # Final fallback with explicit warning
            try:
                from numba import njit, prange
                NUMBA_AVAILABLE = True
                logger.warning(f"âš ï¸ Using direct NUMBA import - WILL cause thread conflicts with {OPTIMAL_WORKERS}")
            except ImportError:
                NUMBA_AVAILABLE = False
                logger.info("ðŸ’¡ Numba not available - using standard NumPy")
                
                # Simple decorator fallbacks
                def njit(*args, **kwargs):
                    def decorator(func): 
                        return func
                    if args and callable(args[0]): 
                        return args[0]
                    return decorator
                
                def prange(*args, **kwargs): 
                    return range(*args, **kwargs)
else:
    NUMBA_AVAILABLE = False
    logger.info(f"ðŸ’¡ M4 Ultra Mode disabled - using standard decorators with {OPTIMAL_WORKERS} thread awareness")
    
    # Simple decorator fallbacks that are thread-aware
    def njit(*args, **kwargs):
        def decorator(func): 
            return func
        if args and callable(args[0]): 
            return args[0]
        return decorator
    
    def prange(*args, **kwargs): 
        return range(*args, **kwargs)

# INDUSTRY STANDARD VALIDATION: Ensure OPTIMAL_WORKERS is properly set
if 'OPTIMAL_WORKERS' in globals():
    logger.info(f"âœ… Thread configuration validated: OPTIMAL_WORKERS = {OPTIMAL_WORKERS}")
    if OPTIMAL_WORKERS > 10:
        logger.warning(f"ðŸš¨ WARNING: OPTIMAL_WORKERS ({OPTIMAL_WORKERS}) > 8 may cause conflicts")
else:
    logger.error("ðŸš¨ CRITICAL: OPTIMAL_WORKERS not defined - this will cause threading issues")
    OPTIMAL_WORKERS = 10  # Emergency fallback
    
# ============================================================================
# ðŸ› ï¸ UTILITY FUNCTIONS ðŸ› ï¸
# ============================================================================

# Define utility functions if not imported from technical_foundation
if not FOUNDATION_AVAILABLE:
    def validate_price_data(prices: List[float], min_length: int = 1) -> bool:
        """Validate price data for calculations"""
        try:
            if not prices or not isinstance(prices, (list, tuple)):
                return False
            if len(prices) < min_length:
                return False
            return all(isinstance(p, (int, float)) and math.isfinite(p) and p > 0 for p in prices)
        except:
            return False
    
    def standardize_arrays(prices, highs=None, lows=None, volumes=None) -> Tuple[List[float], ...]:
        """Standardize arrays to the same length"""
        try:
            # Create a list of arrays to process
            arrays = [prices]
            if highs is not None:
                arrays.append(highs)
            if lows is not None:
                arrays.append(lows)
            if volumes is not None:
                arrays.append(volumes)

            # Check if we have valid data
            if not any(arr and len(arr) > 0 for arr in arrays):
                default_len = 50
                result = [prices] if prices else [[100.0] * default_len]
                if highs is not None:
                    result.append(highs if highs else [100.0] * default_len)
                if lows is not None:
                    result.append(lows if lows else [100.0] * default_len)
                if volumes is not None:
                    result.append(volumes if volumes else [100.0] * default_len)
                return tuple(result)
        
            # Find minimum valid length
            valid_arrays = [arr for arr in arrays if arr and len(arr) > 0]
            min_length = min(len(arr) for arr in valid_arrays)
            if min_length < 20:
                min_length = 20
            
            # Standardize each array to the minimum length
            result = []
        
            # Process prices (always required)
            if not prices or len(prices) == 0:
                result.append([100.0] * min_length)
            else:
                if len(prices) >= min_length:
                    result.append(prices[-min_length:])
                else:
                    extended = list(prices) + [prices[-1]] * (min_length - len(prices))
                    result.append(extended)
        
            # Process highs (optional)
            if highs is not None:
                if not highs or len(highs) == 0:
                    result.append([101.0] * min_length)  # Default for highs is slightly higher
                else:
                    if len(highs) >= min_length:
                        result.append(highs[-min_length:])
                    else:
                        extended = list(highs) + [highs[-1]] * (min_length - len(highs))
                        result.append(extended)
        
            # Process lows (optional)
            if lows is not None:
                if not lows or len(lows) == 0:
                    result.append([99.0] * min_length)  # Default for lows is slightly lower
                else:
                    if len(lows) >= min_length:
                        result.append(lows[-min_length:])
                    else:
                        extended = list(lows) + [lows[-1]] * (min_length - len(lows))
                        result.append(extended)
        
            # Process volumes (optional)
            if volumes is not None:
                if not volumes or len(volumes) == 0:
                    result.append([1000000.0] * min_length)  # Default volume
                else:
                    if len(volumes) >= min_length:
                        result.append(volumes[-min_length:])
                    else:
                        extended = list(volumes) + [volumes[-1]] * (min_length - len(volumes))
                        result.append(extended)
        
            return tuple(result)
        
        except Exception as e:
            if logger:
                logger.warning(f"Array standardization error: {e}")
            else:
                # Optional: handle the case where logger is None
                print(f"Array standardization error: {e}")  # Simple fallback
        
            # Return safe defaults
            default_len = 50
            result = [[100.0] * default_len]  # Default for prices
        
            if highs is not None:
                result.append([101.0] * default_len)  # Default for highs
        
            if lows is not None:
                result.append([99.0] * default_len)  # Default for lows
        
            if volumes is not None:
                result.append([1000000.0] * default_len)  # Default for volumes
        
            return tuple(result)
    
    def safe_division(numerator: float, denominator: float, default: float = 0.0) -> float:
        """Safe division with fallback for zero or invalid denominators"""
        try:
            if denominator == 0 or not math.isfinite(denominator):
                return default
            result = numerator / denominator
            return result if math.isfinite(result) else default
        except:
            return default

# ============================================================================
# ðŸ”§ HELPER FUNCTIONS ðŸ”§
# ============================================================================

def calculate_ema(data: List[float], period: int) -> List[float]:
    """Calculate Exponential Moving Average"""
    if not data:
        return []
    
    if len(data) < period:
        return [sum(data) / len(data)] * len(data)
    
    alpha = 2 / (period + 1)
    ema = [sum(data[:period]) / period]
    
    for price in data[period:]:
        ema.append(alpha * price + (1 - alpha) * ema[-1])
    
    return ema

def calculate_sma(data: List[float], period: int) -> float:
    """Calculate Simple Moving Average"""
    if not data or len(data) < period:
        return 0.0
    
    return sum(data[-period:]) / period

# ============================================================================
# ðŸš€ OPTIMIZED CALCULATION KERNELS ðŸš€
# ============================================================================

@njit
def _ultra_rsi_kernel(prices: np.ndarray, period: int) -> float:
    """
    Optimized RSI calculation kernel
    M4 MacBook optimized with parallel processing
    """
    if len(prices) <= period:
        return 50.0
    
    # Calculate price deltas with SIMD optimization
    deltas = np.zeros(len(prices) - 1, dtype=np.float64)
    for i in prange(1, len(prices)):
        deltas[i-1] = prices[i] - prices[i-1]
    
    # Separate gains and losses with parallel processing
    gains = np.zeros(len(deltas), dtype=np.float64)
    losses = np.zeros(len(deltas), dtype=np.float64)
    
    for i in prange(len(deltas)):
        if deltas[i] > 0:
            gains[i] = deltas[i]
        else:
            losses[i] = -deltas[i]
    
    # Wilder's smoothing with M4 optimization
    avg_gain = np.mean(gains[:period])
    avg_loss = np.mean(losses[:period])
    
    alpha = 1.0 / period
    for i in range(period, len(gains)):
        avg_gain = alpha * gains[i] + (1 - alpha) * avg_gain
        avg_loss = alpha * losses[i] + (1 - alpha) * avg_loss
    
    if avg_loss == 0.0:
        return 100.0
    
    rs = avg_gain / avg_loss
    return float(100.0 - (100.0 / (1.0 + rs)))

@njit
def _ultra_macd_kernel(prices: np.ndarray, fast_period: int, slow_period: int, signal_period: int) -> tuple:
    """
    Optimized MACD calculation kernel
    M4 Silicon optimized with atomic-level precision
    """
    if len(prices) < slow_period + signal_period:
        return (0.0, 0.0, 0.0)
    
    def calculate_ema_ultra(data: np.ndarray, period: int) -> np.ndarray:
        if len(data) == 0:
            return np.array([0.0])
        
        if len(data) < period:
            avg = np.mean(data)
            return np.full(len(data), avg, dtype=np.float64)
        
        alpha = 2.0 / (period + 1.0)
        ema = np.zeros_like(data, dtype=np.float64)
        ema[0] = data[0]
        
        for i in range(1, len(data)):
            ema[i] = alpha * data[i] + (1.0 - alpha) * ema[i-1]
        
        return ema
    
    # Calculate EMAs with parallel optimization
    fast_ema = calculate_ema_ultra(prices, fast_period)
    slow_ema = calculate_ema_ultra(prices, slow_period)
    
    # Ensure arrays are same length
    min_len = min(len(fast_ema), len(slow_ema))
    if min_len == 0:
        return (0.0, 0.0, 0.0)
    
    fast_ema = fast_ema[-min_len:]
    slow_ema = slow_ema[-min_len:]
    
    # Calculate MACD components
    macd_line = fast_ema[-1] - slow_ema[-1]
    
    if len(fast_ema) >= signal_period:
        macd_history = fast_ema[-signal_period:] - slow_ema[-signal_period:]
        signal_line = float(np.mean(macd_history))
    else:
        signal_line = macd_line * 0.9
    
    histogram = macd_line - signal_line
    
    return (float(macd_line), float(signal_line), float(histogram))

@njit
def _ultra_bollinger_kernel(prices: np.ndarray, period: int, std_mult: float) -> tuple:
    """
    Optimized Bollinger Bands calculation kernel
    M4 optimized with parallel standard deviation calculation
    """
    if len(prices) == 0:
        return (0.0, 0.0, 0.0)
    
    if len(prices) < period:
        last_price = float(prices[-1]) if len(prices) > 0 else 0.0
        estimated_std = last_price * 0.02
        upper = last_price + (std_mult * estimated_std)
        lower = last_price - (std_mult * estimated_std)
        return (float(upper), float(last_price), float(lower))
    
    # Calculate SMA with parallel processing
    window_start = len(prices) - period
    price_window = prices[window_start:]
    
    sma = 0.0
    for i in prange(len(price_window)):
        sma += price_window[i]
    sma = sma / period
    
    # Calculate standard deviation with parallel processing
    variance = 0.0
    for i in prange(len(price_window)):
        diff = price_window[i] - sma
        variance += diff * diff
    
    variance = variance / period
    std_dev = math.sqrt(variance)
    
    # Calculate Bollinger Bands
    upper_band = sma + (std_mult * std_dev)
    middle_band = sma
    lower_band = sma - (std_mult * std_dev)
    
    # Ensure mathematical consistency
    if upper_band <= lower_band:
        spread = sma * 0.001
        upper_band = sma + spread
        lower_band = sma - spread
    
    return (float(upper_band), float(middle_band), float(lower_band))

@njit
def _ultra_stochastic_kernel(prices: np.ndarray, highs: np.ndarray, lows: np.ndarray, k_period: int) -> tuple:
    """
    Optimized Stochastic Oscillator kernel
    M4 Silicon parallel processing for momentum detection
    """
    if len(prices) == 0 or len(highs) == 0 or len(lows) == 0:
        return (50.0, 50.0)
    
    min_len = min(len(prices), len(highs), len(lows))
    if min_len < k_period:
        return (50.0, 50.0)
    
    # Get recent period data
    recent_prices = prices[-k_period:]
    recent_highs = highs[-k_period:]
    recent_lows = lows[-k_period:]
    
    # Parallel min/max calculation
    highest_high = recent_highs[0]
    lowest_low = recent_lows[0]
    
    for i in prange(1, len(recent_highs)):
        if recent_highs[i] > highest_high:
            highest_high = recent_highs[i]
        if recent_lows[i] < lowest_low:
            lowest_low = recent_lows[i]
    
    current_close = float(prices[-1])
    
    # Calculate %K
    if highest_high == lowest_low:
        k_percent = 50.0
    else:
        k_percent = ((current_close - lowest_low) / (highest_high - lowest_low)) * 100.0
    
    k_percent = max(0.0, min(100.0, k_percent))
    
    # Calculate %D (3-period SMA of %K)
    d_percent = k_percent * 0.95  # Simplified for performance
    d_percent = max(0.0, min(100.0, d_percent))
    
    return (float(k_percent), float(d_percent))

@njit
def _ultra_vwap_kernel(prices: np.ndarray, volumes: np.ndarray) -> float:
    """
    Optimized VWAP calculation kernel
    M4 optimized volume-weighted average price
    """
    if len(prices) == 0 or len(volumes) == 0:
        return 0.0
    
    if len(prices) != len(volumes):
        min_len = min(len(prices), len(volumes))
        prices = prices[:min_len]
        volumes = volumes[:min_len]
    
    total_volume = np.sum(volumes)
    if total_volume <= 0:
        return 0.0
    
    weighted_sum = 0.0
    for i in prange(len(prices)):
        weighted_sum += prices[i] * volumes[i]
    
    return weighted_sum / total_volume

# ============================================================================
# ðŸŽ¯ UNIFIED CALCULATION DISPATCHER ðŸŽ¯
# ============================================================================

class UltraOptimizedCalculations:
    """
    Unified calculation dispatcher for prediction engine integration
    
    Automatically selects optimal calculation method based on:
    - Available optimization libraries (NumPy, Numba)
    - System capabilities (M4 optimization)
    - Data size and complexity
    """
    
    def __init__(self):
        """Initialize the unified calculation dispatcher"""
        self.ultra_mode = M4_ULTRA_MODE and NUMPY_AVAILABLE and NUMBA_AVAILABLE
        self.calculation_count = 0
        self.performance_metrics = self._initialize_performance_metrics()
        self.calculation_cache = {}
        self.last_cache_clear = time.time()

        # Use the optimized worker count from foundation
        self.core_count = OPTIMAL_WORKERS
        
        if logger:
            logger.info(f"ðŸ”¥ Calculation Engine: {'M4 ULTRA MODE' if self.ultra_mode else 'STANDARD MODE'}")
            logger.info(f"ðŸ”¥ CPU Cores: {self.core_count}")
            logger.info("ðŸ”¥ Ready for calculations")
    
    def _initialize_performance_metrics(self) -> Dict[str, Any]:
        """Initialize comprehensive performance tracking"""
        return {
            'total_calculations': 0,
            'successful_operations': 0,
            'failed_operations': 0,
            'average_response_time': 0.0,
            'cache_hits': 0,
            'cache_misses': 0,
            'rsi': {'count': 0, 'total_time': 0.0, 'avg_time': 0.0},
            'macd': {'count': 0, 'total_time': 0.0, 'avg_time': 0.0},
            'bollinger_bands': {'count': 0, 'total_time': 0.0, 'avg_time': 0.0},
            'vwap': {'count': 0, 'total_time': 0.0, 'avg_time': 0.0},
            'stochastic': {'count': 0, 'total_time': 0.0, 'avg_time': 0.0},
            'adx': {'count': 0, 'total_time': 0.0, 'avg_time': 0.0},
            'obv': {'count': 0, 'total_time': 0.0, 'avg_time': 0.0}
        }
    
    def clear_cache(self) -> None:
        """Clear calculation cache for memory management"""
        try:
            current_time = time.time()
            
            # Clear cache every hour
            if current_time - self.last_cache_clear > 3600:
                self.calculation_cache.clear()
                self.last_cache_clear = current_time
                if logger:
                    logger.debug("ðŸ§¹ Calculation cache cleared")
                
                # Reset performance metrics periodically
                for method in self.performance_metrics:
                    if isinstance(self.performance_metrics[method], dict):
                        if 'count' in self.performance_metrics[method]:
                            self.performance_metrics[method]['count'] = 0
                            self.performance_metrics[method]['total_time'] = 0.0
                            self.performance_metrics[method]['avg_time'] = 0.0
                            
        except Exception as e:
            if logger:
                logger.debug(f"Cache clear error: {e}")
    
    def _log_performance(self, method: str, duration: float) -> None:
        """Log performance metrics for optimization tracking"""
        try:
            if method not in self.performance_metrics:
                self.performance_metrics[method] = {'count': 0, 'total_time': 0.0, 'avg_time': 0.0}
            
            metrics = self.performance_metrics[method]
            metrics['count'] += 1
            metrics['total_time'] += duration
            metrics['avg_time'] = metrics['total_time'] / metrics['count']
            
            self.calculation_count += 1
            self.performance_metrics['successful_operations'] += 1
            
            # Clear cache periodically
            if self.calculation_count % 50 == 0:
                self.clear_cache()
            
            # Log performance every 100 calculations
            if self.calculation_count % 100 == 0 and logger:
                logger.debug(f"ðŸš€ Performance: {method} avg: {metrics['avg_time']*1000:.2f}ms")
                
        except Exception as e:
            if logger:
                logger.debug(f"Performance logging error: {e}")
    
    def get_performance_report(self) -> Dict[str, Any]:
        """Get comprehensive performance report"""
        try:
            total_calculations = sum(
                metrics.get('count', 0) for metrics in self.performance_metrics.values() 
                if isinstance(metrics, dict) and 'count' in metrics
            )
            
            report = {
                'total_calculations': total_calculations,
                'successful_operations': self.performance_metrics.get('successful_operations', 0),
                'failed_operations': self.performance_metrics.get('failed_operations', 0),
                'cache_hits': self.performance_metrics.get('cache_hits', 0),
                'cache_misses': self.performance_metrics.get('cache_misses', 0),
                'ultra_mode_active': self.ultra_mode,
                'core_count': self.core_count,
                'methods': {}
            }
            
            for method, metrics in self.performance_metrics.items():
                if isinstance(metrics, dict) and 'count' in metrics:
                    report['methods'][method] = {
                        'count': metrics['count'],
                        'avg_time_ms': metrics['avg_time'] * 1000,
                        'total_time_seconds': metrics['total_time'],
                        'performance_class': 'ultra' if self.ultra_mode else 'standard'
                    }
            
            return report
            
        except Exception as e:
            if logger:
                logger.warning(f"Performance report error: {e}")
            return {'error': str(e)}

# ============================================================================
# ðŸ“ˆ RSI, MACD, and BOLLINGER BANDS METHODS ðŸ“ˆ
# ============================================================================

    def calculate_rsi(self, prices: List[float], period: int = 14) -> float:
        """Calculate RSI with thread-safe optimization - FAIL FAST VERSION"""
        try:
            start_time = time.time()
            
            # Validate input data
            if not prices or len(prices) < period + 1:
                return 50.0
            
            # Check cache first
            cache_key = f"rsi_{str(hash(tuple(prices[-50:])))[:8]}_{period}"
            if cache_key in self.calculation_cache:
                self.performance_metrics['cache_hits'] += 1
                return self.calculation_cache[cache_key]
            
            self.performance_metrics['cache_misses'] += 1
            
            # Thread-safe ultra mode calculation - FAIL FAST
            if self.ultra_mode and len(prices) >= period:
                try:
                    # Import thread-safe numba from foundation
                    from technical_foundation import m4_libs
                    if not (hasattr(m4_libs, 'njit') and m4_libs.njit is not None):
                        raise ImportError("Foundation njit not available")
                    
                    njit = m4_libs.njit
                    
                    @njit
                    def _rsi_kernel_thread_safe(prices_arr, period_val):
                        if len(prices_arr) <= period_val:
                            return 50.0
                        
                        # Calculate price changes
                        changes = np.zeros(len(prices_arr) - 1)
                        for i in range(1, len(prices_arr)):
                            changes[i-1] = prices_arr[i] - prices_arr[i-1]
                        
                        # Calculate gains and losses
                        gains = np.zeros(len(changes))
                        losses = np.zeros(len(changes))
                        
                        for i in range(len(changes)):
                            if changes[i] > 0:
                                gains[i] = changes[i]
                            else:
                                losses[i] = -changes[i]
                        
                        # Calculate average gain and loss for first period
                        avg_gain = np.mean(gains[:period_val])
                        avg_loss = np.mean(losses[:period_val])
                        
                        # Apply Wilder's smoothing for remaining periods
                        for i in range(period_val, len(gains)):
                            avg_gain = (avg_gain * (period_val - 1) + gains[i]) / period_val
                            avg_loss = (avg_loss * (period_val - 1) + losses[i]) / period_val
                        
                        # Calculate RSI
                        if avg_loss == 0:
                            return 100.0
                        else:
                            rs = avg_gain / avg_loss
                            return 100.0 - (100.0 / (1.0 + rs))
                    
                    prices_array = np.array(prices, dtype=np.float64)
                    if np.all(np.isfinite(prices_array)):
                        result = _rsi_kernel_thread_safe(prices_array, period)
                        result = max(0.0, min(100.0, float(result)))
                        self.calculation_cache[cache_key] = result
                        self._log_performance('rsi', time.time() - start_time)
                        return result
                        
                except Exception as ultra_error:
                    # FAIL FAST: If ultra mode fails, propagate error immediately
                    if "NUMBA_NUM_THREADS" in str(ultra_error):
                        raise RuntimeError(f"Thread configuration conflict in RSI calculation: {ultra_error}")
                    raise ultra_error
            
            # Standard NumPy calculation - NO fallback chain
            prices_array = np.array(prices)
            deltas = np.diff(prices_array)
            gains = np.where(deltas > 0, deltas, 0)
            losses = np.where(deltas < 0, -deltas, 0)
            
            if len(gains) < period or len(losses) < period:
                return 50.0
            
            # Use simple moving average for initial calculation
            avg_gain = np.mean(gains[:period])
            avg_loss = np.mean(losses[:period])
            
            # Apply Wilder's smoothing for remaining periods
            for i in range(period, len(gains)):
                avg_gain = (avg_gain * (period - 1) + gains[i]) / period
                avg_loss = (avg_loss * (period - 1) + losses[i]) / period
            
            if avg_loss == 0:
                result = 100.0
            else:
                rs = avg_gain / avg_loss
                result = 100.0 - (100.0 / (1.0 + rs))
            
            result = max(0.0, min(100.0, result))
            self.calculation_cache[cache_key] = result
            self._log_performance('rsi', time.time() - start_time)
            return float(result)
            
        except Exception as e:
            # FAIL FAST: Propagate errors immediately
            if logger:
                logger.error(f"RSI calculation failed: {e}")
            raise e

    def calculate_macd(self, prices: List[float], fast: int = 12, 
                    slow: int = 26, signal: int = 9) -> Tuple[float, float, float]:
        """Calculate MACD with thread-safe optimization - FAIL FAST VERSION"""
        try:
            start_time = time.time()
            
            if not validate_price_data(prices, slow + signal):
                raise ValueError(f"Insufficient data for MACD calculation: need {slow + signal}, got {len(prices) if prices else 0}")
            
            # Thread-safe ultra mode calculation - FAIL FAST
            if self.ultra_mode:
                try:
                    # Import thread-safe numba from foundation
                    from technical_foundation import m4_libs
                    if not (hasattr(m4_libs, 'njit') and m4_libs.njit is not None):
                        raise ImportError("Foundation njit not available")
                    
                    njit = m4_libs.njit
                    
                    @njit
                    def _macd_kernel_thread_safe(prices_arr, fast_period, slow_period, signal_period):
                        if len(prices_arr) < slow_period:
                            return 0.0, 0.0, 0.0
                        
                        # Calculate EMAs
                        fast_multiplier = 2.0 / (fast_period + 1.0)
                        slow_multiplier = 2.0 / (slow_period + 1.0)
                        
                        fast_ema = np.empty(len(prices_arr))
                        slow_ema = np.empty(len(prices_arr))
                        
                        # Initialize with SMAs
                        fast_sma = 0.0
                        slow_sma = 0.0
                        
                        for i in range(fast_period):
                            fast_sma += prices_arr[i]
                        fast_ema[fast_period-1] = fast_sma / fast_period
                        
                        for i in range(slow_period):
                            slow_sma += prices_arr[i]
                        slow_ema[slow_period-1] = slow_sma / slow_period
                        
                        # Calculate EMAs
                        for i in range(fast_period, len(prices_arr)):
                            fast_ema[i] = (prices_arr[i] - fast_ema[i-1]) * fast_multiplier + fast_ema[i-1]
                        
                        for i in range(slow_period, len(prices_arr)):
                            slow_ema[i] = (prices_arr[i] - slow_ema[i-1]) * slow_multiplier + slow_ema[i-1]
                        
                        # Calculate MACD line
                        macd_line = fast_ema[-1] - slow_ema[-1]
                        
                        # Calculate signal line (EMA of MACD)
                        signal_multiplier = 2.0 / (signal_period + 1.0)
                        macd_values = np.empty(len(prices_arr))
                        
                        for i in range(len(prices_arr)):
                            if i >= slow_period-1:
                                macd_values[i] = fast_ema[i] - slow_ema[i]
                            else:
                                macd_values[i] = 0.0
                        
                        # Initialize signal line with SMA
                        signal_start_idx = slow_period + signal_period - 2
                        if signal_start_idx >= len(prices_arr):
                            signal_line = macd_line
                        else:
                            signal_sma = 0.0
                            for i in range(slow_period-1, min(signal_start_idx+1, len(prices_arr))):
                                signal_sma += macd_values[i]
                            signal_line = signal_sma / signal_period
                            
                            # Calculate signal EMA
                            for i in range(signal_start_idx+1, len(prices_arr)):
                                signal_line = (macd_values[i] - signal_line) * signal_multiplier + signal_line
                        
                        # Calculate histogram
                        histogram = macd_line - signal_line
                        
                        return macd_line, signal_line, histogram
                    
                    prices_array = np.array(prices, dtype=np.float64)
                    if np.all(np.isfinite(prices_array)):
                        result = _macd_kernel_thread_safe(prices_array, fast, slow, signal)
                        self._log_performance('macd', time.time() - start_time)
                        return result
                        
                except Exception as ultra_error:
                    # FAIL FAST: If ultra mode fails, propagate error immediately
                    if "NUMBA_NUM_THREADS" in str(ultra_error):
                        raise RuntimeError(f"Thread configuration conflict in MACD calculation: {ultra_error}")
                    raise ultra_error
            
            # Standard NumPy calculation - NO fallback chain
            prices_array = np.array(prices)
            
            # Calculate EMAs
            fast_ema = np.zeros_like(prices_array)
            slow_ema = np.zeros_like(prices_array)
            
            # Initialize EMAs
            fast_ema[0] = prices_array[0]
            slow_ema[0] = prices_array[0]
            
            # Calculate fast and slow EMAs
            alpha_fast = 2.0 / (fast + 1.0)
            alpha_slow = 2.0 / (slow + 1.0)
            
            for i in range(1, len(prices_array)):
                fast_ema[i] = alpha_fast * prices_array[i] + (1.0 - alpha_fast) * fast_ema[i-1]
                slow_ema[i] = alpha_slow * prices_array[i] + (1.0 - alpha_slow) * slow_ema[i-1]
            
            # Calculate MACD line
            macd_line = fast_ema[-1] - slow_ema[-1]
            
            # Calculate signal line (EMA of MACD line)
            if len(prices) > signal:
                macd_line_history = fast_ema[-signal:] - slow_ema[-signal:]
                signal_line = np.mean(macd_line_history)  # Simplified
            else:
                signal_line = macd_line
            
            # Calculate histogram
            histogram = macd_line - signal_line
            
            self._log_performance('macd_numpy', time.time() - start_time)
            return float(macd_line), float(signal_line), float(histogram)
            
        except Exception as e:
            # FAIL FAST: Propagate errors immediately
            if logger:
                logger.error(f"MACD calculation failed: {e}")
            raise e

    def calculate_bollinger_bands(self, prices: List[float], period: int = 20, std_mult: float = 2.0) -> tuple:
        """Calculate Bollinger Bands with thread-safe optimization - FAIL FAST VERSION"""
        try:
            start_time = time.time()
            
            if not prices or len(prices) < period:
                raise ValueError(f"Insufficient data for Bollinger Bands: need {period}, got {len(prices) if prices else 0}")
            
            # Thread-safe ultra mode calculation - FAIL FAST
            if self.ultra_mode and len(prices) >= period:
                try:
                    # Import thread-safe numba from foundation
                    from technical_foundation import m4_libs
                    if not (hasattr(m4_libs, 'njit') and m4_libs.njit is not None):
                        raise ImportError("Foundation njit not available")
                    
                    njit = m4_libs.njit
                    
                    @njit
                    def _bollinger_kernel_thread_safe(prices_arr, period_val, std_multiplier):
                        if len(prices_arr) < period_val:
                            return 0.0, 0.0, 0.0
                        
                        # Use the most recent period for calculation
                        recent_prices = prices_arr[-period_val:]
                        
                        # Calculate Simple Moving Average
                        sma = np.mean(recent_prices)
                        
                        # Calculate Standard Deviation
                        variance = 0.0
                        for price in recent_prices:
                            diff = price - sma
                            variance += diff * diff
                        variance /= len(recent_prices)
                        std_dev = np.sqrt(variance)
                        
                        # Calculate Bollinger Bands
                        upper_band = sma + (std_multiplier * std_dev)
                        middle_band = sma
                        lower_band = sma - (std_multiplier * std_dev)
                        
                        return upper_band, middle_band, lower_band
                    
                    prices_array = np.array(prices, dtype=np.float64)
                    if np.all(np.isfinite(prices_array)):
                        result = _bollinger_kernel_thread_safe(prices_array, period, std_mult)
                        # Ensure mathematical consistency
                        upper, middle, lower = result
                        if upper <= lower:
                            spread = middle * 0.001
                            upper = middle + spread
                            lower = middle - spread
                        
                        result = (float(upper), float(middle), float(lower))
                        self._log_performance('bollinger_bands', time.time() - start_time)
                        return result
                        
                except Exception as ultra_error:
                    # FAIL FAST: If ultra mode fails, propagate error immediately
                    if "NUMBA_NUM_THREADS" in str(ultra_error):
                        raise RuntimeError(f"Thread configuration conflict in Bollinger Bands calculation: {ultra_error}")
                    raise ultra_error
            
            # Standard calculation - NO fallback chain
            recent_prices = prices[-period:]
            
            # Calculate Simple Moving Average
            sma = sum(recent_prices) / len(recent_prices)
            
            # Calculate Standard Deviation
            variance = sum((price - sma) ** 2 for price in recent_prices) / len(recent_prices)
            std_dev = math.sqrt(variance)
            
            # Calculate Bollinger Bands
            upper_band = sma + (std_mult * std_dev)
            middle_band = sma
            lower_band = sma - (std_mult * std_dev)
            
            # Ensure mathematical consistency
            if upper_band <= lower_band:
                spread = sma * 0.001
                upper_band = sma + spread
                lower_band = sma - spread
            
            result = (float(upper_band), float(middle_band), float(lower_band))
            self._log_performance('bollinger_bands', time.time() - start_time)
            return result
            
        except Exception as e:
            # FAIL FAST: Propagate errors immediately
            if logger:
                logger.error(f"Bollinger Bands calculation failed: {e}")
            raise e

# ============================================================================
# ðŸ“Š STOCHASTIC, VWAP, and ADX METHODS ðŸ“Š
# ============================================================================

    def calculate_stochastic(self, prices: List[float], highs: List[float], 
                        lows: List[float], k_period: int = 14, d_period: int = 3) -> Tuple[float, float]:
        """Calculate Stochastic oscillator with robust array handling"""
        try:
            start_time = time.time()
            
            # Validate and standardize input arrays
            if not prices or not highs or not lows:
                return 50.0, 50.0
            
            # Standardize arrays to ensure same length
            try:
                prices, highs, lows = standardize_arrays(prices, highs, lows)
            except Exception as e:
                if logger:
                    logger.debug(f"Array standardization error: {e}")
                return 50.0, 50.0
            
            if len(prices) < k_period:
                return 50.0, 50.0
            
            # Ultra mode calculation
            if self.ultra_mode:
                try:
                    prices_array = np.array(prices, dtype=np.float64)
                    highs_array = np.array(highs, dtype=np.float64)
                    lows_array = np.array(lows, dtype=np.float64)
                    
                    if (np.all(np.isfinite(prices_array)) and 
                        np.all(np.isfinite(highs_array)) and 
                        np.all(np.isfinite(lows_array))):
                        result = _ultra_stochastic_kernel(prices_array, highs_array, lows_array, k_period)
                        self._log_performance('stochastic', time.time() - start_time)
                        return result
                except Exception as e:
                    if logger:
                        logger.debug(f"Ultra Stochastic failed, using NumPy: {e}")
            
            # Standard NumPy calculation
            prices_array = np.array(prices)
            highs_array = np.array(highs)
            lows_array = np.array(lows)
            
            # Get recent values for calculations
            recent_highs = highs_array[-k_period:]
            recent_lows = lows_array[-k_period:]
            current_close = prices_array[-1]
            
            highest_high = np.max(recent_highs)
            lowest_low = np.min(recent_lows)
            
            if highest_high == lowest_low:
                return 50.0, 50.0
            
            # Calculate %K
            k = 100 * (current_close - lowest_low) / (highest_high - lowest_low)
            
            # Calculate %D (3-period SMA of %K)
            if len(prices) >= k_period + d_period:
                # Calculate k values for the last d_period points
                k_values = []
                for i in range(d_period):
                    idx = -(i+1)
                    c = prices_array[idx]
                    h = np.max(highs_array[idx-k_period+1:idx+1])
                    l = np.min(lows_array[idx-k_period+1:idx+1])
                    if h != l:
                        k_val = 100 * (c - l) / (h - l)
                        k_values.append(k_val)
                    else:
                        k_values.append(50.0)
                
                d = np.mean(k_values)
            else:
                d = k  # Simplified when not enough data
            
            k = max(0.0, min(100.0, k))
            d = max(0.0, min(100.0, d))
            
            self._log_performance('stochastic_numpy', time.time() - start_time)
            return float(k), float(d)
            
        except Exception as e:
            if logger:
                logger.warning(f"Stochastic calculation error: {e}")
            self.performance_metrics['failed_operations'] += 1
            return 50.0, 50.0

    def calculate_vwap(self, prices: List[float], volumes: List[float]) -> Optional[float]:
        """Calculate VWAP with comprehensive error handling"""
        try:
            start_time = time.time()
            
            if not prices or not volumes:
                return None
            
            # Standardize arrays to prevent length mismatches
            try:
                prices, volumes = standardize_arrays(prices, volumes)
            except Exception as e:
                if logger:
                    logger.debug(f"VWAP array standardization error: {e}")
                return None
            
            if not prices or not volumes:
                return None
            
            # Ultra mode calculation
            if self.ultra_mode:
                try:
                    prices_array = np.array(prices, dtype=np.float64)
                    volumes_array = np.array(volumes, dtype=np.float64)
                    
                    if (np.all(np.isfinite(prices_array)) and 
                        np.all(np.isfinite(volumes_array)) and
                        np.all(volumes_array > 0)):
                        result = _ultra_vwap_kernel(prices_array, volumes_array)
                        if result > 0:
                            self._log_performance('vwap', time.time() - start_time)
                            return float(result)
                except Exception as e:
                    if logger:
                        logger.debug(f"Ultra VWAP failed, using NumPy: {e}")
            
            # Standard NumPy calculation
            prices_array = np.array(prices)
            volumes_array = np.array(volumes)
            
            # Calculate VWAP
            total_volume = np.sum(volumes_array)
            if total_volume <= 0:
                return None
            
            weighted_prices = prices_array * volumes_array
            vwap = np.sum(weighted_prices) / total_volume
            
            self._log_performance('vwap_numpy', time.time() - start_time)
            return float(vwap)
            
        except Exception as e:
            if logger:
                logger.warning(f"VWAP calculation error: {e}")
            self.performance_metrics['failed_operations'] += 1
            return None

    def calculate_adx(self, highs: List[float], lows: List[float], 
                    prices: List[float], period: int = 14) -> float:
        """Calculate ADX with enhanced error handling"""
        try:
            start_time = time.time()
            
            if not prices or len(prices) < period + 1:
                return 25.0
            
            # Standard NumPy calculation for ADX
            highs_array = np.array(highs)
            lows_array = np.array(lows)
            prices_array = np.array(prices)
            
            if len(highs_array) < period + 1 or len(lows_array) < period + 1:
                return 25.0
            
            # Calculate True Range
            tr = np.zeros(len(prices) - 1)
            for i in range(1, len(prices)):
                high_low = highs_array[i] - lows_array[i]
                high_close = abs(highs_array[i] - prices_array[i-1])
                low_close = abs(lows_array[i] - prices_array[i-1])
                tr[i-1] = max(high_low, high_close, low_close)
            
            # Calculate +DM and -DM
            plus_dm = np.zeros(len(prices) - 1)
            minus_dm = np.zeros(len(prices) - 1)
            
            for i in range(1, len(prices)):
                up_move = highs_array[i] - highs_array[i-1]
                down_move = lows_array[i-1] - lows_array[i]
                
                if up_move > down_move and up_move > 0:
                    plus_dm[i-1] = up_move
                else:
                    plus_dm[i-1] = 0
                    
                if down_move > up_move and down_move > 0:
                    minus_dm[i-1] = down_move
                else:
                    minus_dm[i-1] = 0
            
            # Calculate smoothed TR, +DM, -DM
            tr_period = np.sum(tr[:period])
            plus_dm_period = np.sum(plus_dm[:period])
            minus_dm_period = np.sum(minus_dm[:period])
            
            # Calculate +DI and -DI
            plus_di = 100 * plus_dm_period / tr_period if tr_period > 0 else 0
            minus_di = 100 * minus_dm_period / tr_period if tr_period > 0 else 0
            
            # Calculate DX
            dx = 100 * abs(plus_di - minus_di) / (plus_di + minus_di) if (plus_di + minus_di) > 0 else 0
            
            # Simplified ADX (normally an average of DX)
            adx = dx
            
            self._log_performance('adx', time.time() - start_time)
            return max(0.0, min(100.0, float(adx)))
            
        except Exception as e:
            if logger:
                logger.warning(f"ADX calculation error: {e}")
            self.performance_metrics['failed_operations'] += 1
            return 25.0

    def calculate_obv(self, closes: List[float], volumes: List[float]) -> float:
        """Calculate On-Balance Volume"""
        try:
            start_time = time.time()
            
            if not closes or not volumes or len(closes) != len(volumes):
                return 0.0
            
            if len(closes) < 2:
                return 0.0
            
            # NumPy vectorized calculation
            closes_array = np.array(closes)
            volumes_array = np.array(volumes)
            
            # Create price change direction array
            price_changes = np.diff(closes_array)
            directions = np.zeros(len(price_changes))
            directions[price_changes > 0] = 1
            directions[price_changes < 0] = -1
            
            # Calculate OBV
            volume_contribution = volumes_array[1:] * directions
            obv = np.sum(volume_contribution)
            
            self._log_performance('obv', time.time() - start_time)
            return float(obv)
            
        except Exception as e:
            if logger:
                logger.warning(f"OBV calculation error: {e}")
            self.performance_metrics['failed_operations'] += 1
            return 0.0

# ============================================================================
# ðŸ”¬ ENHANCED CALCULATION METHODS ðŸ”¬
# ============================================================================

class EnhancedCalculations:
    """
    Enhanced calculations for advanced technical analysis
    Additional calculation methods for complex indicators and analysis
    """
    
    def __init__(self, ultra_calc_instance):
        """Initialize enhanced calculations with ultra calc instance"""
        self.ultra_calc = ultra_calc_instance
        if logger:
            logger.info("ðŸ”¬ Enhanced calculations module initialized")
    
    def calculate_rsi(self, prices: List[float], period: int = 14) -> float:
        """Delegate RSI calculation to ultra_calc"""
        return self.ultra_calc.calculate_rsi(prices, period)
    
    def calculate_obv(self, closes: List[float], volumes: List[float]) -> float:
        """Delegate OBV calculation to ultra_calc"""
        return self.ultra_calc.calculate_obv(closes, volumes)
    
    def calculate_macd(self, prices: List[float], fast: int = 12, 
                      slow: int = 26, signal: int = 9) -> Tuple[float, float, float]:
        """Delegate MACD calculation to ultra_calc"""
        return self.ultra_calc.calculate_macd(prices, fast, slow, signal)
    
    def calculate_bollinger_bands(self, prices: List[float], period: int = 20, 
                                num_std: float = 2.0) -> Tuple[float, float, float]:
        """Delegate Bollinger Bands calculation to ultra_calc"""
        return self.ultra_calc.calculate_bollinger_bands(prices, period, num_std)
    
    def calculate_adx(self, highs: List[float], lows: List[float], closes: List[float], period: int = 14) -> float:
        """
        Calculate Average Directional Index (ADX) for trend strength measurement
    
        Args:
            highs: List of high prices
            lows: List of low prices  
            closes: List of closing prices
            period: Period for ADX calculation (default 14)
        
        Returns:
            ADX value (0-100, higher values indicate stronger trends)
        """
        try:
            # Validate inputs
            if not highs or not lows or not closes:
                return 25.0  # Neutral ADX value
        
            # Ensure all arrays are the same length
            min_length = min(len(highs), len(lows), len(closes))
            if min_length < period + 1:
                return 25.0  # Not enough data
        
            # Take the last min_length values to ensure consistency
            highs = highs[-min_length:]
            lows = lows[-min_length:]
            closes = closes[-min_length:]
        
            # Calculate True Range (TR)
            tr_values = []
            for i in range(1, len(closes)):
                high_low = highs[i] - lows[i]
                high_close_prev = abs(highs[i] - closes[i-1])
                low_close_prev = abs(lows[i] - closes[i-1])
                tr = max(high_low, high_close_prev, low_close_prev)
                tr_values.append(tr)
        
            if len(tr_values) < period:
                return 25.0
        
            # Calculate Directional Movement (+DM and -DM)
            plus_dm_values = []
            minus_dm_values = []
        
            for i in range(1, len(highs)):
                move_up = highs[i] - highs[i-1]
                move_down = lows[i-1] - lows[i]
            
                if move_up > move_down and move_up > 0:
                    plus_dm = move_up
                else:
                    plus_dm = 0
            
                if move_down > move_up and move_down > 0:
                    minus_dm = move_down
                else:
                    minus_dm = 0
            
                plus_dm_values.append(plus_dm)
                minus_dm_values.append(minus_dm)
        
            if len(plus_dm_values) < period or len(minus_dm_values) < period:
                return 25.0
        
            # Calculate smoothed TR, +DM, -DM (using simple moving average for simplicity)
            smoothed_tr = sum(tr_values[-period:]) / period
            smoothed_plus_dm = sum(plus_dm_values[-period:]) / period
            smoothed_minus_dm = sum(minus_dm_values[-period:]) / period
        
            # Calculate +DI and -DI
            if smoothed_tr == 0:
                return 25.0
        
            plus_di = 100 * smoothed_plus_dm / smoothed_tr
            minus_di = 100 * smoothed_minus_dm / smoothed_tr
        
            # Calculate DX
            di_sum = plus_di + minus_di
            if di_sum == 0:
                return 25.0
        
            dx = 100 * abs(plus_di - minus_di) / di_sum
        
            # ADX is typically a smoothed version of DX
            # For simplicity, we'll use DX as ADX approximation
            adx = dx
        
            # Ensure ADX is within valid range
            return max(0.0, min(100.0, float(adx)))
        
        except Exception as e:
            # Handle logging safely without accessing unknown attributes
            try:
                # Try to use foundation logger if available
                if 'logger' in globals() and logger is not None:
                    logger.warning(f"ADX calculation error: {e}")
            except:
                # If logger fails, use basic print for debugging
                print(f"ADX calculation error: {e}")
        
            return 25.0  # Return neutral value on error

    def calculate_ema(self, prices: List[float], period: int) -> List[float]:
        """Calculate Exponential Moving Average with optimized handling"""
        try:
            if not validate_price_data(prices):
                return [0.0] * len(prices) if prices else [0.0]
            
            # NumPy vectorized calculation
            if NUMPY_AVAILABLE:
                try:
                    prices_array = np.array(prices, dtype=np.float64)
                    if len(prices) < period:
                        avg = np.mean(prices_array)
                        return [float(avg)] * len(prices)
                    
                    alpha = 2.0 / (period + 1.0)
                    ema = np.zeros_like(prices_array)
                    ema[0] = prices_array[0]
                    
                    for i in range(1, len(prices_array)):
                        ema[i] = alpha * prices_array[i] + (1.0 - alpha) * ema[i-1]
                    
                    return ema.tolist()
                except Exception as e:
                    if logger:
                        logger.debug(f"NumPy EMA failed, using standard: {e}")
            
            # Standard EMA calculation
            if len(prices) == 0:
                return [0.0]
            
            if len(prices) < period:
                avg = sum(prices) / len(prices)
                return [avg] * len(prices)
            
            ema = [prices[0]]
            alpha = 2 / (period + 1)
            
            for price in prices[1:]:
                ema.append(alpha * price + (1 - alpha) * ema[-1])
            
            return ema
            
        except Exception as e:
            if logger:
                logger.warning(f"EMA calculation error: {e}")
            return [prices[0] if prices else 0.0] * len(prices) if prices else [0.0]
    
    def calculate_sma(self, prices: List[float], period: int) -> float:
        """Calculate Simple Moving Average"""
        try:
            if not validate_price_data(prices):
                return 0.0
            
            if len(prices) < period:
                return sum(prices) / len(prices) if prices else 0.0
            
            return sum(prices[-period:]) / period
            
        except Exception as e:
            if logger:
                logger.warning(f"SMA calculation error: {e}")
            return 0.0
    
    def calculate_stochastic(self, prices: List[float], highs: List[float], 
                            lows: List[float], k_period: int = 14, d_period: int = 3) -> Tuple[float, float]:
        """Calculate Stochastic oscillator for EnhancedCalculations class"""
        try:
            if not prices or not highs or not lows:
                return 50.0, 50.0
        
            # Ensure all arrays are the same length
            min_length = min(len(prices), len(highs), len(lows))
            if min_length < k_period:
                return 50.0, 50.0
        
            prices = prices[-min_length:]
            highs = highs[-min_length:]
            lows = lows[-min_length:]
        
            # Calculate %K
            current_close = prices[-1]
            highest_high = max(highs[-k_period:])
            lowest_low = min(lows[-k_period:])
        
            if highest_high == lowest_low:
                k_value = 50.0
            else:
                k_value = ((current_close - lowest_low) / (highest_high - lowest_low)) * 100.0
        
            # Calculate %D (simple moving average of %K)
            # For simplicity, use current %K as %D (in practice, you'd average several %K values)
            d_value = k_value
        
            return max(0.0, min(100.0, float(k_value))), max(0.0, min(100.0, float(d_value)))
        
        except Exception as e:
            if logger:
                logger.warning(f"Enhanced Stochastic calculation error: {e}")
            return 50.0, 50.0

    def calculate_ichimoku_cloud(self, highs: List[float], lows: List[float], 
                               closes: List[float], tenkan_period: int = 9, 
                               kijun_period: int = 26, senkou_b_period: int = 52) -> Dict[str, float]:
        """Calculate Ichimoku Cloud components"""
        try:
            if not validate_price_data(highs) or not validate_price_data(lows) or not validate_price_data(closes):
                return {
                    'tenkan_sen': 0.0,
                    'kijun_sen': 0.0,
                    'senkou_span_a': 0.0,
                    'senkou_span_b': 0.0,
                    'chikou_span': 0.0
                }
            
            # Tenkan-sen (Conversion Line): (highest high + lowest low) / 2 for tenkan_period
            if len(highs) >= tenkan_period and len(lows) >= tenkan_period:
                tenkan_sen_high = max(highs[-tenkan_period:])
                tenkan_sen_low = min(lows[-tenkan_period:])
                tenkan_sen = (tenkan_sen_high + tenkan_sen_low) / 2
            else:
                tenkan_sen = closes[-1] if closes else 0.0
            
            # Kijun-sen (Base Line): (highest high + lowest low) / 2 for kijun_period
            if len(highs) >= kijun_period and len(lows) >= kijun_period:
                kijun_sen_high = max(highs[-kijun_period:])
                kijun_sen_low = min(lows[-kijun_period:])
                kijun_sen = (kijun_sen_high + kijun_sen_low) / 2
            else:
                kijun_sen = closes[-1] if closes else 0.0
            
            # Senkou Span A (Leading Span A): (Tenkan-sen + Kijun-sen) / 2
            senkou_span_a = (tenkan_sen + kijun_sen) / 2
            
            # Senkou Span B (Leading Span B): (highest high + lowest low) / 2 for senkou_b_period
            if len(highs) >= senkou_b_period and len(lows) >= senkou_b_period:
                senkou_span_b_high = max(highs[-senkou_b_period:])
                senkou_span_b_low = min(lows[-senkou_b_period:])
                senkou_span_b = (senkou_span_b_high + senkou_span_b_low) / 2
            else:
                senkou_span_b = closes[-1] if closes else 0.0
            
            # Chikou Span (Lagging Span): Current close shifted back kijun_period
            chikou_span = closes[-1] if closes else 0.0
            
            return {
                'tenkan_sen': tenkan_sen,
                'kijun_sen': kijun_sen,
                'senkou_span_a': senkou_span_a,
                'senkou_span_b': senkou_span_b,
                'chikou_span': chikou_span
            }
            
        except Exception as e:
            if logger:
                logger.warning(f"Ichimoku cloud calculation error: {e}")
            return {
                'tenkan_sen': 0.0,
                'kijun_sen': 0.0,
                'senkou_span_a': 0.0,
                'senkou_span_b': 0.0,
                'chikou_span': 0.0
            }
    
    def calculate_pivot_points(self, high: float, low: float, close: float, 
                             method: str = 'standard') -> Dict[str, float]:
        """Calculate various pivot point levels"""
        try:
            if not all(isinstance(x, (int, float)) and x > 0 for x in [high, low, close]):
                return {'pivot': 0.0, 'r1': 0.0, 'r2': 0.0, 'r3': 0.0, 's1': 0.0, 's2': 0.0, 's3': 0.0}
            
            # Standard pivot points
            if method == 'standard':
                pivot = (high + low + close) / 3
                r1 = (2 * pivot) - low
                r2 = pivot + (high - low)
                r3 = high + 2 * (pivot - low)
                s1 = (2 * pivot) - high
                s2 = pivot - (high - low)
                s3 = low - 2 * (high - pivot)
            
            # Fibonacci pivot points
            elif method == 'fibonacci':
                pivot = (high + low + close) / 3
                r1 = pivot + 0.382 * (high - low)
                r2 = pivot + 0.618 * (high - low)
                r3 = pivot + 1.000 * (high - low)
                s1 = pivot - 0.382 * (high - low)
                s2 = pivot - 0.618 * (high - low)
                s3 = pivot - 1.000 * (high - low)
            
            # Camarilla pivot points
            elif method == 'camarilla':
                pivot = (high + low + close) / 3
                r1 = close + 1.1 * (high - low) / 12
                r2 = close + 1.1 * (high - low) / 6
                r3 = close + 1.1 * (high - low) / 4
                s1 = close - 1.1 * (high - low) / 12
                s2 = close - 1.1 * (high - low) / 6
                s3 = close - 1.1 * (high - low) / 4
            
            # Woodie's pivot points
            elif method == 'woodie':
                pivot = (high + low + 2 * close) / 4
                r1 = (2 * pivot) - low
                r2 = pivot + (high - low)
                r3 = high + 2 * (pivot - low)
                s1 = (2 * pivot) - high
                s2 = pivot - (high - low)
                s3 = low - 2 * (high - pivot)
            
            # Default to standard
            else:
                pivot = (high + low + close) / 3
                r1 = (2 * pivot) - low
                r2 = pivot + (high - low)
                r3 = high + 2 * (pivot - low)
                s1 = (2 * pivot) - high
                s2 = pivot - (high - low)
                s3 = low - 2 * (high - pivot)
            
            return {
                'pivot': pivot,
                'r1': r1,
                'r2': r2,
                'r3': r3,
                's1': s1,
                's2': s2,
                's3': s3
            }
            
        except Exception as e:
            if logger:
                logger.warning(f"Pivot points calculation error: {e}")
            return {'pivot': 0.0, 'r1': 0.0, 'r2': 0.0, 'r3': 0.0, 's1': 0.0, 's2': 0.0, 's3': 0.0}
        
# ============================================================================
# ðŸŽ¯ GLOBAL INSTANCES AND MODULE EXPORTS ðŸŽ¯
# ============================================================================

# Create global calculation engines for easy access
try:
    ultra_calc = UltraOptimizedCalculations()
    enhanced_calc = EnhancedCalculations(ultra_calc)
    
    if logger:
        logger.info("ðŸ”¥ Global calculation engines initialized")
        logger.info(f"âœ… Ultra-optimized calculations: {'READY' if ultra_calc.ultra_mode else 'STANDARD MODE'}")
        logger.info("âœ… Enhanced calculations: READY")
        
except Exception as e:
    if logger:
        logger.error(f"ðŸš¨ CRITICAL SYSTEM FAILURE: Failed to initialize calculation engines: {e}")
    
    # ðŸ›¡ï¸ FAIL-FAST SECURITY IMPLEMENTATION ðŸ›¡ï¸
    # NO SYNTHETIC DATA - NO DANGEROUS FALLBACKS - SYSTEM MUST HALT
    
    class FailFastSecurityError(Exception):
        """Critical security exception when real calculation engines unavailable"""
        pass
    
    # Immediately raise critical error - NO fallbacks allowed
    error_msg = (
        f"ðŸš¨ BILLION DOLLAR TRADING SYSTEM SECURITY BREACH ðŸš¨\n"
        f"CRITICAL FAILURE: Cannot initialize UltraOptimizedCalculations\n"
        f"ERROR: {str(e)}\n"
        f"SECURITY POLICY: NO synthetic data allowed in trading system\n"
        f"ACTION REQUIRED: Fix calculation engine dependencies immediately\n"
        f"SYSTEM STATUS: HALTED - Trading operations suspended\n"
        f"FAIL-FAST PROTECTION: Active - Preventing use of fake data\n"
        f"ðŸ’° MONEY PROTECTION: Your capital is protected from bad calculations"
    )
    
    if logger:
        logger.error(error_msg)
    
    # Create error-only instances that prevent any trading operations
    class FailFastCalculations:
        """
        ðŸ›¡ï¸ FAIL-FAST SECURITY CLASS ðŸ›¡ï¸
        
        This class PREVENTS trading with synthetic data by raising exceptions
        for ALL calculation attempts. Protects billion-dollar trading system
        from catastrophic losses due to fake data.
        
        SECURITY PRINCIPLE: Better to miss trades than trade on fake data
        """
        
        def __init__(self):
            self.ultra_mode = False
            self.calculation_count = 0
            self.performance_metrics = {'system_status': 'CRITICAL_FAILURE'}
            self.calculation_cache = {}
            self._system_compromised = True
            
            # Log the security breach
            if logger:
                logger.error("ðŸ›¡ï¸ FAIL-FAST SECURITY: Initialized emergency protection mode")
                logger.error("ðŸ’° MONEY PROTECTION: All calculations will fail to prevent losses")
        
        def _raise_security_error(self, method_name: str):
            """Raise security error for any calculation attempt"""
            error_msg = (
                f"ðŸš¨ TRADING SYSTEM SECURITY BREACH ðŸš¨\n"
                f"ATTEMPTED CALCULATION: {method_name}\n"
                f"SECURITY VIOLATION: Real calculation engine unavailable\n"
                f"FAIL-FAST PROTECTION: Preventing use of synthetic data\n"
                f"SYSTEM STATUS: Trading operations suspended\n"
                f"ACTION REQUIRED: Fix UltraOptimizedCalculations initialization\n"
                f"ðŸ’° MONEY PROTECTION: Your capital is safe from bad calculations\n"
                f"\nThis error prevents billion-dollar losses from fake data!"
            )
            raise FailFastSecurityError(error_msg)
        
        def calculate_rsi(self, prices, period=14):
            """SECURITY: Fail-fast instead of returning fake RSI values"""
            self._raise_security_error("calculate_rsi")
            
        def calculate_macd(self, prices, fast=12, slow=26, signal=9):
            """SECURITY: Fail-fast instead of returning fake MACD values"""
            self._raise_security_error("calculate_macd")
            
        def calculate_bollinger_bands(self, prices, period=20, std_mult=2.0):
            """SECURITY: Fail-fast instead of returning fake Bollinger Band values"""
            self._raise_security_error("calculate_bollinger_bands")
                
        def calculate_stochastic(self, prices, highs, lows, k_period=14, d_period=3):
            """SECURITY: Fail-fast instead of returning fake stochastic values"""
            self._raise_security_error("calculate_stochastic")
            
        def calculate_vwap(self, prices, volumes):
            """SECURITY: Fail-fast instead of returning fake VWAP values"""
            self._raise_security_error("calculate_vwap")
                
        def calculate_adx(self, highs, lows, prices, period=14):
            """SECURITY: Fail-fast instead of returning fake ADX values"""
            self._raise_security_error("calculate_adx")
            
        def calculate_obv(self, closes, volumes):
            """SECURITY: Fail-fast instead of returning fake OBV values"""
            self._raise_security_error("calculate_obv")
    
    # Create fail-fast security instances
    ultra_calc = FailFastCalculations()
    enhanced_calc = FailFastCalculations()
    
    # Log final security status
    if logger:
        logger.error("ðŸ›¡ï¸ FAIL-FAST SECURITY: Emergency protection mode active")
        logger.error("ðŸ’° BILLION DOLLAR PROTECTION: System will reject all calculations until fixed")
        logger.error("âš¡ NEXT STEPS: Fix UltraOptimizedCalculations dependencies to resume trading")

# Expose version information for integration diagnostics
VERSION = {
    'version': '9.0',
    'name': 'Fail-Fast Secure Edition',
    'ultra_mode': hasattr(ultra_calc, 'ultra_mode') and ultra_calc.ultra_mode,
    'numpy_available': NUMPY_AVAILABLE,
    'numba_available': NUMBA_AVAILABLE,
    'foundation_available': FOUNDATION_AVAILABLE,
    'database_available': database is not None if 'database' in globals() else False,
    'security_mode': hasattr(ultra_calc, '_system_compromised')
}

# Primary exports for prediction_engine.py and bot.py
__all__ = [
    # Main calculation engines
    'UltraOptimizedCalculations',
    'EnhancedCalculations',
    
    # Global instances (may be fail-fast security instances)
    'ultra_calc',
    'enhanced_calc',
    
    # Core utility functions
    'validate_price_data',
    'standardize_arrays',
    'safe_division',
    'calculate_ema',
    'calculate_sma',
    
    # System status flags
    'FOUNDATION_AVAILABLE',
    'NUMPY_AVAILABLE',
    'NUMBA_AVAILABLE',
    'M4_ULTRA_MODE',
    'VERSION',
    
    # Security classes
    'FailFastSecurityError'
]

# Now create the instance
ultra_calc = UltraOptimizedCalculations()

# Add these to exports  
__all__ += [
    'calculate_rsi',
    'calculate_macd', 
    'calculate_bollinger_bands',
    'calculate_stochastic',
    'calculate_vwap',
    'calculate_adx',
    'calculate_obv'
]

# Initialize the system if this module is run directly
if __name__ == "__main__":
    print("ðŸ›¡ï¸ Technical Calculations Module v9.0 - Fail-Fast Secure Edition ðŸ›¡ï¸")
    
    if hasattr(ultra_calc, '_system_compromised'):
        print("ðŸš¨ CRITICAL: System in fail-fast security mode")
        print("ðŸ’° PROTECTION: Trading operations suspended to protect capital")
        print("âš¡ ACTION: Fix UltraOptimizedCalculations initialization")
    else:
        print(f"Ultra Mode: {'ENABLED' if M4_ULTRA_MODE and NUMPY_AVAILABLE and NUMBA_AVAILABLE else 'DISABLED'}")
        print("âœ… Security: All systems operational")
    
    print(f"NumPy: {'Available' if NUMPY_AVAILABLE else 'Not Available'}")
    print(f"Numba: {'Available' if NUMBA_AVAILABLE else 'Not Available'}")
    print(f"Foundation: {'Available' if FOUNDATION_AVAILABLE else 'Not Available'}")
    print(f"Database: {'Connected' if 'database' in globals() and database is not None else 'Not Connected'}")
    print(f"Security Mode: {'ACTIVE' if hasattr(ultra_calc, '_system_compromised') else 'NORMAL'}")
    
    if not hasattr(ultra_calc, '_system_compromised'):
        print("\nâœ… Technical Calculations Module ready for billion-dollar trading")
    else:
        print("\nðŸ›¡ï¸ Technical Calculations Module in protective fail-fast mode")

# ============================================================================
# ðŸ›¡ï¸ END OF FAIL-FAST SECURE TECHNICAL_CALCULATIONS.PY ðŸ›¡ï¸
# ============================================================================  
